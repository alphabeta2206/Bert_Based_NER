{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "from spacy import displacy  \n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"book.txt\",\"r\") as f:\n",
    "    text=f.read().replace(\"\\n\\n\",\" \").replace(\"\\n\",\" \")\n",
    "    chapters=text.split(\"CHAPTER\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter1=chapters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenising the names of the document\n",
    "doc=nlp(chapter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=s[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually _took a watch out of its waistcoat-pocket_, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent=list(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Alice,\n",
       " Alice,\n",
       " Rabbit,\n",
       " Alice,\n",
       " Alice,\n",
       " Alice,\n",
       " First,\n",
       " ORANGE MARMALADE,\n",
       " Alice,\n",
       " four thousand miles,\n",
       " Alice,\n",
       " Latitude,\n",
       " Alice,\n",
       " Latitude,\n",
       " Longitude,\n",
       " Antipathies,\n",
       " New Zealand,\n",
       " Australia,\n",
       " Alice,\n",
       " Dinah,\n",
       " Alice,\n",
       " Dinah,\n",
       " Dinah,\n",
       " the White Rabbit,\n",
       " Alice,\n",
       " Rabbit,\n",
       " Alice,\n",
       " three,\n",
       " Alice,\n",
       " first,\n",
       " second,\n",
       " about fifteen inches,\n",
       " Alice,\n",
       " Alice,\n",
       " Alice,\n",
       " half,\n",
       " Alice,\n",
       " DRINK ME,\n",
       " Alice,\n",
       " first,\n",
       " Alice,\n",
       " turkey,\n",
       " Alice,\n",
       " only ten inches,\n",
       " First,\n",
       " a few minutes,\n",
       " Alice,\n",
       " Alice,\n",
       " one,\n",
       " Alice,\n",
       " this minute,\n",
       " two,\n",
       " Alice,\n",
       " two,\n",
       " EAT ME,\n",
       " Alice,\n",
       " one,\n",
       " Alice]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=s[1]\n",
    "ent=list(sentence.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice]\n"
     ]
    }
   ],
   "source": [
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n",
      "ORG\n"
     ]
    }
   ],
   "source": [
    "for i in ent:\n",
    "    print(i.text)\n",
    "    print(i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people=[]\n",
    "for x in ent:\n",
    "    if x.label_ == \"PERSON\":\n",
    "        people.append(x.text)\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?”"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice - PROPN\n",
      "was - AUX\n",
      "beginning - VERB\n",
      "to - PART\n",
      "get - VERB\n",
      "very - ADV\n",
      "tired - ADJ\n",
      "of - ADP\n",
      "sitting - VERB\n",
      "by - ADP\n",
      "her - PRON\n",
      "sister - NOUN\n",
      "on - ADP\n",
      "the - DET\n",
      "bank - NOUN\n",
      ", - PUNCT\n",
      "and - CCONJ\n",
      "of - ADP\n",
      "having - VERB\n",
      "nothing - PRON\n",
      "to - PART\n",
      "do - VERB\n",
      ": - PUNCT\n",
      "once - ADV\n",
      "or - CCONJ\n",
      "twice - ADV\n",
      "she - PRON\n",
      "had - AUX\n",
      "peeped - VERB\n",
      "into - ADP\n",
      "the - DET\n",
      "book - NOUN\n",
      "her - PRON\n",
      "sister - NOUN\n",
      "was - AUX\n",
      "reading - VERB\n",
      ", - PUNCT\n",
      "but - CCONJ\n",
      "it - PRON\n",
      "had - VERB\n",
      "no - DET\n",
      "pictures - NOUN\n",
      "or - CCONJ\n",
      "conversations - NOUN\n",
      "in - ADP\n",
      "it - PRON\n",
      ", - PUNCT\n",
      "“ - PUNCT\n",
      "and - CCONJ\n",
      "what - PRON\n",
      "is - VERB\n",
      "the - DET\n",
      "use - NOUN\n",
      "of - ADP\n",
      "a - DET\n",
      "book - NOUN\n",
      ", - PUNCT\n",
      "” - PUNCT\n",
      "thought - VERB\n",
      "Alice - PROPN\n",
      "“ - PUNCT\n",
      "without - ADP\n",
      "pictures - NOUN\n",
      "or - CCONJ\n",
      "conversations - NOUN\n",
      "? - PUNCT\n",
      "” - PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in p:\n",
    "    print(token.text,\"-\",token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sister',\n",
       " 'bank',\n",
       " 'book',\n",
       " 'sister',\n",
       " 'pictures',\n",
       " 'conversations',\n",
       " 'use',\n",
       " 'book',\n",
       " 'pictures',\n",
       " 'conversations']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting nouns from the tokens using pos tag \n",
    "nouns=[]\n",
    "for token in p:\n",
    "    if token.pos_==\"NOUN\":\n",
    "        nouns.append(token.text)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Alice,\n",
       " her sister,\n",
       " the bank,\n",
       " nothing,\n",
       " she,\n",
       " the book,\n",
       " her sister,\n",
       " it,\n",
       " no pictures,\n",
       " conversations,\n",
       " it,\n",
       " what,\n",
       " the use,\n",
       " a book,\n",
       " Alice,\n",
       " pictures,\n",
       " conversations]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noun_chunks\n",
    "chunks=list(p.noun_chunks)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moment down\n",
      "_never\n",
      "miles down\n",
      "_very\n",
      "heads downward\n",
      "way down\n",
      "time round\n",
      "door about\n",
      "inches high\n",
      "things indeed\n",
      "_very\n",
      "use now\n"
     ]
    }
   ],
   "source": [
    "#verbs and patterns --  textacy(extracting patterns in the data)\n",
    "patterns=[{\"POS\":\"NOUN\"},{\"POS\":\"ADV\"}]\n",
    "verb_matcher=textacy.extract.token_matches(doc, patterns=patterns)\n",
    "\n",
    "for i in verb_matcher:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatisation-- root of the word\n",
    "#plural's reduced to the lemma or singular form.\n",
    "p=s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind - mind\n",
      "day - day\n",
      "pleasure - pleasure\n",
      "daisy - daisy\n",
      "chain - chain\n",
      "trouble - trouble\n",
      "daisies - daisy\n",
      "eyes - eye\n"
     ]
    }
   ],
   "source": [
    "for word in p:\n",
    "    if word.pos_ == \"NOUN\":\n",
    "        print(word.text,\"-\",word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualsing the data with enitities extracted\n",
    "#style=\"ent\" for marking the enitities.\n",
    "html=displacy.render(doc,style=\"ent\",jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"visualised.html\",\"w\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
